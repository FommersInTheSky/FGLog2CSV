# FGLog2CSV
# ðŸ§© Log Fieldname to CSV Converter

A lightweight, memory-efficient Python tool that converts log-like text files containing key-value pairs into structured CSV files â€” even for very large input files (hundreds of MB or more).

It has been tested on Fortigate and Fortianalyzer log output files.

---

## ðŸ’¡ Overview

This script reads log files where each line follows the pattern:
```
"itime=1764342944","date=""2025-11-28""","time=""16:15:44""","devid=""FG100FTK20000000""", ...
```
Each field uses the syntax:
```
fieldname=fieldvalue
```
If the field value is text, itâ€™s surrounded by additional quotes (`""`):
```
date=""2025-11-28""
```

The script:

1. **Detects all unique fieldnames** found across the entire file.
2. **Generates a CSV file** where:
   - Columns = fieldnames
   - Each line = one input record
   - Missing values = empty cells
3. Writes the output **sequentially**, keeping memory usage minimal.

---

## ðŸš€ Features

- âœ… Handles files of any size (tested > 300â€¯MB)
- âœ… Displays **progress percentage** for both scanning and writing phases
- âœ… UTFâ€‘8 and quote-safe
- âœ… Two-pass sequential algorithm for accuracy and low RAM use
- âœ… Automatically names the output file as `<input_filename>.csv` in the current working directory

---

## ðŸ› ï¸ Requirements

- **Python 3.8+**
- No third-party libraries required

---

## ðŸ“¦ Installation

No installation required â€” just download the script.

## Optionâ€¯1: Clone the repository
```
bash
git clone https://github.com/yourusername/log-to-csv.git
cd log-to-csv
```

## Optionâ€¯2: Download the single file
Download parse_log_to_csv.py directly from the repository and place it anywhere on your system.

---

## ðŸ§° Usage
Run the script from your terminal, passing your input log filename:
```
python parse_log_to_csv.py /path/to/input.txt
```
The CSV is written automatically as: ./input.txt.csv

Example:
```
python parse_log_to_csv.py firewall_logs.txt
```
This creates: firewall_logs.txt.csv

## âš™ï¸ Howâ€¯Itâ€¯Works
1ï¸âƒ£â€¯Field Discovery Phase -> scans the file once to find every distinct fieldname.  
2ï¸âƒ£â€¯CSVâ€¯Writing Phase -> reâ€‘reads the file and streams each parsed record directly to CSV.

Progress percentage is printed based on bytes processed versus total file size.

## ðŸ“ˆ Performance
- Constant memory footprint (suitable for multiâ€‘GB logs)
- Progress updates everyâ€¯â‰ˆâ€¯5â€¯MB processed
- Gracefully ignores malformed or excess quotes
- No temporary data or intermediate buffers
